{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import lightgbm as lgb\n",
    "\n",
    "data_path = r'F:\\contest\\ATEC\\dataset'\n",
    "data_files_paths = glob.glob(data_path + '\\*.csv')\n",
    "#data_files_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] get data 0 is ok\n",
      "[+] get data 1 is ok\n",
      "[+] get data 2 is ok\n",
      "[+] get data 3 is ok\n",
      "[+] get data 4 is ok\n"
     ]
    }
   ],
   "source": [
    "data_reader = pd.read_csv(data_files_paths[-1], iterator=True)\n",
    "traindata = {}\n",
    "for i in range(5):\n",
    "    traindata[i] = data_reader.get_chunk(200000)\n",
    "    # 因为疏忽写文件时将index保留了，但是在读时应该去掉\n",
    "    print('[+] get data {} is ok'.format(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-073e921e002b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "np.isnan(traindata[0].f234).sum()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[f5] nan is 199825\n",
      "[f20] nan is 207448\n",
      "[f21] nan is 207448\n",
      "[f22] nan is 207448\n",
      "[f23] nan is 207448\n",
      "[f24] nan is 207585\n",
      "[f25] nan is 207585\n",
      "[f26] nan is 207585\n",
      "[f27] nan is 207585\n",
      "[f28] nan is 211036\n",
      "[f29] nan is 211036\n",
      "[f30] nan is 211036\n",
      "[f31] nan is 211036\n",
      "[f32] nan is 341887\n",
      "[f33] nan is 341887\n",
      "[f34] nan is 341887\n",
      "[f35] nan is 341887\n",
      "[f36] nan is 925781\n",
      "[f37] nan is 925781\n",
      "[f38] nan is 925781\n",
      "[f39] nan is 925781\n",
      "[f40] nan is 925781\n",
      "[f41] nan is 925781\n",
      "[f42] nan is 925781\n",
      "[f43] nan is 925781\n",
      "[f44] nan is 925781\n",
      "[f45] nan is 925781\n",
      "[f46] nan is 925781\n",
      "[f47] nan is 925781\n",
      "[f48] nan is 341661\n",
      "[f49] nan is 341661\n",
      "[f50] nan is 341661\n",
      "[f51] nan is 341661\n",
      "[f52] nan is 207448\n",
      "[f53] nan is 207448\n",
      "[f54] nan is 341661\n",
      "[f55] nan is 341661\n",
      "[f56] nan is 341661\n",
      "[f57] nan is 341661\n",
      "[f58] nan is 341661\n",
      "[f59] nan is 341661\n",
      "[f60] nan is 341661\n",
      "[f61] nan is 341661\n",
      "[f62] nan is 341661\n",
      "[f63] nan is 341661\n",
      "[f64] nan is 270515\n",
      "[f65] nan is 270515\n",
      "[f66] nan is 270515\n",
      "[f67] nan is 270515\n",
      "[f68] nan is 270515\n",
      "[f69] nan is 270515\n",
      "[f70] nan is 270515\n",
      "[f71] nan is 270515\n",
      "[f72] nan is 273904\n",
      "[f73] nan is 273904\n",
      "[f74] nan is 273904\n",
      "[f75] nan is 273904\n",
      "[f76] nan is 270515\n",
      "[f77] nan is 270515\n",
      "[f78] nan is 270515\n",
      "[f79] nan is 270515\n",
      "[f80] nan is 270515\n",
      "[f81] nan is 270515\n",
      "[f82] nan is 270515\n",
      "[f83] nan is 270515\n",
      "[f84] nan is 270515\n",
      "[f85] nan is 270515\n",
      "[f86] nan is 270515\n",
      "[f87] nan is 270515\n",
      "[f88] nan is 270515\n",
      "[f89] nan is 270515\n",
      "[f90] nan is 270515\n",
      "[f91] nan is 270515\n",
      "[f92] nan is 270515\n",
      "[f93] nan is 270515\n",
      "[f94] nan is 270515\n",
      "[f95] nan is 270515\n",
      "[f96] nan is 270515\n",
      "[f97] nan is 270515\n",
      "[f98] nan is 270515\n",
      "[f99] nan is 270515\n",
      "[f100] nan is 270515\n",
      "[f101] nan is 270515\n",
      "[f102] nan is 286285\n",
      "[f103] nan is 286285\n",
      "[f104] nan is 286285\n",
      "[f105] nan is 286285\n",
      "[f106] nan is 286285\n",
      "[f107] nan is 273904\n",
      "[f108] nan is 273904\n",
      "[f109] nan is 273904\n",
      "[f110] nan is 273904\n",
      "[f111] nan is 270515\n",
      "[f112] nan is 270515\n",
      "[f113] nan is 270515\n",
      "[f114] nan is 270515\n",
      "[f115] nan is 270515\n",
      "[f116] nan is 270515\n",
      "[f117] nan is 270515\n",
      "[f118] nan is 270515\n",
      "[f119] nan is 270515\n",
      "[f120] nan is 270515\n",
      "[f121] nan is 270515\n",
      "[f122] nan is 270515\n",
      "[f123] nan is 270515\n",
      "[f124] nan is 270515\n",
      "[f125] nan is 270515\n",
      "[f126] nan is 270515\n",
      "[f127] nan is 270515\n",
      "[f128] nan is 270515\n",
      "[f129] nan is 270515\n",
      "[f130] nan is 270515\n",
      "[f131] nan is 270515\n",
      "[f132] nan is 270515\n",
      "[f133] nan is 270515\n",
      "[f134] nan is 270515\n",
      "[f135] nan is 270515\n",
      "[f136] nan is 270515\n",
      "[f137] nan is 270515\n",
      "[f138] nan is 270515\n",
      "[f139] nan is 270515\n",
      "[f140] nan is 270515\n",
      "[f141] nan is 270515\n",
      "[f142] nan is 270515\n",
      "[f143] nan is 270515\n",
      "[f144] nan is 270515\n",
      "[f145] nan is 270515\n",
      "[f146] nan is 270515\n",
      "[f147] nan is 270515\n",
      "[f148] nan is 270515\n",
      "[f149] nan is 270515\n",
      "[f150] nan is 270515\n",
      "[f151] nan is 270515\n",
      "[f152] nan is 270515\n",
      "[f153] nan is 270515\n",
      "[f154] nan is 270515\n",
      "[f155] nan is 273904\n",
      "[f156] nan is 273904\n",
      "[f157] nan is 273904\n",
      "[f158] nan is 273904\n",
      "[f159] nan is 273904\n",
      "[f160] nan is 273904\n",
      "[f161] nan is 919\n",
      "[f162] nan is 919\n",
      "[f163] nan is 919\n",
      "[f164] nan is 919\n",
      "[f165] nan is 919\n",
      "[f166] nan is 136021\n",
      "[f167] nan is 136021\n",
      "[f168] nan is 136021\n",
      "[f169] nan is 136021\n",
      "[f170] nan is 136021\n",
      "[f171] nan is 136021\n",
      "[f172] nan is 136021\n",
      "[f173] nan is 136021\n",
      "[f174] nan is 136021\n",
      "[f175] nan is 136021\n",
      "[f176] nan is 136021\n",
      "[f177] nan is 136021\n",
      "[f178] nan is 136021\n",
      "[f179] nan is 136021\n",
      "[f180] nan is 136021\n",
      "[f181] nan is 136021\n",
      "[f182] nan is 136021\n",
      "[f183] nan is 136021\n",
      "[f184] nan is 136021\n",
      "[f185] nan is 136021\n",
      "[f186] nan is 136021\n",
      "[f187] nan is 136021\n",
      "[f188] nan is 136021\n",
      "[f189] nan is 136021\n",
      "[f190] nan is 136021\n",
      "[f191] nan is 136021\n",
      "[f192] nan is 136021\n",
      "[f193] nan is 136021\n",
      "[f194] nan is 136021\n",
      "[f195] nan is 136021\n",
      "[f196] nan is 136021\n",
      "[f197] nan is 136021\n",
      "[f198] nan is 136021\n",
      "[f199] nan is 136021\n",
      "[f200] nan is 136021\n",
      "[f201] nan is 136021\n",
      "[f202] nan is 136021\n",
      "[f203] nan is 136021\n",
      "[f204] nan is 136021\n",
      "[f205] nan is 136021\n",
      "[f206] nan is 136021\n",
      "[f207] nan is 136021\n",
      "[f208] nan is 136021\n",
      "[f209] nan is 136021\n",
      "[f210] nan is 136021\n",
      "[f211] nan is 919\n",
      "[f212] nan is 919\n",
      "[f213] nan is 919\n",
      "[f214] nan is 919\n",
      "[f215] nan is 919\n",
      "[f216] nan is 919\n",
      "[f217] nan is 919\n",
      "[f218] nan is 919\n",
      "[f219] nan is 919\n",
      "[f220] nan is 919\n",
      "[f221] nan is 919\n",
      "[f222] nan is 919\n",
      "[f223] nan is 919\n",
      "[f224] nan is 919\n",
      "[f225] nan is 919\n",
      "[f226] nan is 919\n",
      "[f227] nan is 919\n",
      "[f228] nan is 919\n",
      "[f229] nan is 919\n",
      "[f230] nan is 919\n",
      "[f231] nan is 919\n",
      "[f232] nan is 919\n",
      "[f233] nan is 919\n",
      "[f234] nan is 919\n",
      "[f235] nan is 919\n",
      "[f236] nan is 919\n",
      "[f237] nan is 919\n",
      "[f238] nan is 919\n",
      "[f239] nan is 919\n",
      "[f240] nan is 919\n",
      "[f241] nan is 919\n",
      "[f242] nan is 919\n",
      "[f243] nan is 919\n",
      "[f244] nan is 919\n",
      "[f245] nan is 919\n",
      "[f246] nan is 919\n",
      "[f247] nan is 919\n",
      "[f248] nan is 919\n",
      "[f249] nan is 919\n",
      "[f250] nan is 919\n",
      "[f251] nan is 919\n",
      "[f252] nan is 919\n",
      "[f253] nan is 919\n",
      "[f254] nan is 136021\n",
      "[f255] nan is 136021\n",
      "[f256] nan is 136021\n",
      "[f257] nan is 136021\n",
      "[f258] nan is 136021\n",
      "[f259] nan is 136021\n",
      "[f260] nan is 136021\n",
      "[f261] nan is 136021\n",
      "[f262] nan is 136021\n",
      "[f263] nan is 136021\n",
      "[f264] nan is 136021\n",
      "[f265] nan is 136021\n",
      "[f266] nan is 136021\n",
      "[f267] nan is 136021\n",
      "[f268] nan is 136021\n",
      "[f269] nan is 136021\n",
      "[f270] nan is 136021\n",
      "[f271] nan is 136021\n",
      "[f272] nan is 136021\n",
      "[f273] nan is 136021\n",
      "[f274] nan is 136021\n",
      "[f275] nan is 136021\n",
      "[f276] nan is 136021\n",
      "[f277] nan is 136021\n",
      "[f278] nan is 207585\n",
      "[f279] nan is 207585\n",
      "[f280] nan is 207585\n",
      "[f281] nan is 207585\n",
      "[f282] nan is 207585\n",
      "[f283] nan is 207585\n",
      "[f284] nan is 207585\n",
      "[f285] nan is 207585\n",
      "[f286] nan is 207585\n",
      "[f287] nan is 207585\n",
      "[f288] nan is 207585\n",
      "[f289] nan is 207585\n",
      "[f290] nan is 207585\n",
      "[f291] nan is 207585\n",
      "[f292] nan is 207585\n",
      "[f293] nan is 207585\n",
      "[f294] nan is 207585\n",
      "[f295] nan is 207585\n",
      "[f296] nan is 207585\n",
      "[f297] nan is 207585\n",
      "[+] concating data 0 is ok\n",
      "[+] concating data 1 is ok\n",
      "[+] concating data 2 is ok\n",
      "[+] concating data 3 is ok\n",
      "[+] concating data 4 is ok\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "cols = list(traindata[0].columns)\n",
    "cols.remove('id')\n",
    "#cols.remove('Unnamed: 0')\n",
    "cols.remove('label')\n",
    "cols.remove('date')\n",
    "\n",
    "nan_col = []\n",
    "for i in cols:\n",
    "    column_fea = pd.DataFrame()\n",
    "    for j in range(5):\n",
    "        # 将某一特征全部数据合并\n",
    "        column = traindata[j][[i, 'label']].copy()\n",
    "        column_fea = pd.concat([column_fea, column])\n",
    "    if np.isnan(column_fea[[i]]).sum()[0] > 0:\n",
    "        print('[{}] nan is {}'.format(i, np.isnan(column_fea[[i]]).sum()[0]))\n",
    "        if np.isnan(column_fea[[i]]).sum()[0] > 200000:\n",
    "            nan_col.append(i)\n",
    "            \n",
    "for i in nan_col:\n",
    "    cols.remove(i)\n",
    "    \n",
    "train_fir = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    train_mid = traindata[i][cols + ['label']].copy()\n",
    "    train_fir = pd.concat([train_fir, train_mid])\n",
    "    print('[+] concating data {}'.format(i), 'is ok')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(data_files_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=10, min_child_samples=100,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(max_depth=10, min_child_samples=100)\n",
    "tra = train_fir.iloc[0:700000]\n",
    "tes = train_fir.iloc[700000:]\n",
    "lg.fit(tra[cols], tra['label'])\n",
    "\n",
    "# test = pd.read_csv(data_files_paths[0])\n",
    "# out = lg.predict_proba(test[cols])\n",
    "# sub = test[['id']].copy()\n",
    "# sub['score'] = out[:, 1]\n",
    "# sub.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = lg.predict_proba(tes[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.413830376940133"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve \n",
    "y = tes['label']\n",
    "pred = res[:,2]\n",
    "def score(y,pred): \n",
    "    fpr, tpr, thresholds = roc_curve(y, pred, pos_label=1) \n",
    "    score=0.4*tpr[np.where(fpr>=0.001)[0][0]]+0.3*tpr[np.where(fpr>=0.005)[0][0]]+0.3*tpr[np.where(fpr>=0.01)[0][0]] \n",
    "    return score \n",
    "score(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
