{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"F:/contest/ATEC/train.csv\")\n",
    "# data_test = pd.read_csv(\"F:/contest/ATEC/test.csv\")\n",
    "data_train = data_train[data_train.label != -1].drop(['date', 'id'], axis = 1)\n",
    "# data_test = data_test.drop(['date', 'id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#暂时去掉标签为-1的数据\n",
    "# data_train = data_train[data_train.label != -1]\n",
    "\n",
    "#计算缺失值个数\n",
    "# data_train['miss'] = data_train.apply(lambda x: x.isnull().sum(), axis = 1)\n",
    "# data_test['miss'] = data_test.applt(lambda x: x.isnull().sum())\n",
    "\n",
    "# 添加缺失变量\n",
    "data_train['ifexist5'] = np.where(data_train.f5.isnull() == True, -1, 1 )\n",
    "data_train['ifexist20-23'] = np.where(data_train.f20.isnull() == True, -1, 1 )\n",
    "data_train['ifexist24-27'] = np.where(data_train.f24.isnull() == True, -1, 1)\n",
    "data_train['ifexist28-31'] = np.where(data_train.f28.isnull() == True, -1, 1)\n",
    "data_train['ifexist32-35'] = np.where(data_train.f32.isnull() == True, -1, 1)\n",
    "data_train['ifexist36-47'] = np.where(data_train.f36.isnull() == True, -1, 1)\n",
    "data_train['ifexist48-51'] = np.where(data_train.f48.isnull() == True, -1, 1)\n",
    "data_train['ifexist52-53'] = np.where(data_train.f52.isnull() == True, -1, 1)\n",
    "data_train['ifexist54-63'] = np.where(data_train.f54.isnull() == True, -1, 1)\n",
    "data_train['ifexist64-71'] = np.where(data_train.f64.isnull() == True, -1, 1)\n",
    "data_train['ifexist72-75'] = np.where(data_train.f72.isnull() == True, -1, 1)\n",
    "data_train['ifexist76-101'] = np.where(data_train.f76.isnull() == True, -1, 1)\n",
    "data_train['ifexist102-106'] = np.where(data_train.f102.isnull() == True, -1, 1)\n",
    "data_train['ifexist107-110'] = np.where(data_train.f107.isnull() == True, -1, 1)\n",
    "data_train['ifexist111-154'] = np.where(data_train.f111.isnull() == True, -1, 1)\n",
    "data_train['ifexist155-160'] = np.where(data_train.f155.isnull() == True, -1, 1)\n",
    "data_train['ifexist161-165'] = np.where(data_train.f161.isnull() == True, -1, 1)\n",
    "data_train['ifexist166-210'] = np.where(data_train.f166.isnull() == True, -1, 1)\n",
    "data_train['ifexist211-253'] = np.where(data_train.f211.isnull() == True, -1, 1)\n",
    "data_train['ifexist254-277'] = np.where(data_train.f254.isnull() == True, -1, 1)\n",
    "data_train['ifexist278-297'] = np.where(data_train.f278.isnull() == True, -1, 1)\n",
    "\n",
    "\n",
    "#缺失值填充\n",
    "# median = []\n",
    "# for i in data_train.columns:\n",
    "#     tmp = data_train[i].describe()\n",
    "#     if tmp[-1] > 3 * tmp[-2]:\n",
    "#         median.append(i)\n",
    "\n",
    "\n",
    "data_train= data_train.fillna(data_train.mean())\n",
    "# data_train[data_train.label == 1 ] = data_train[data_train.label == 1].fillna(data_train[data_train.label == 1].mean())\n",
    "# data_train[data_train.label == 0 ] = data_train[data_train.label == 0].fillna(data_train[data_train.label == 0].mean())\n",
    "# mean = [i for i in data_train.columns if i not in median]\n",
    "# data_train[data_train.label == 0 ] = data_train[data_train.label == 0].fillna(data_train[data_train.label == 0].mean()[mean])\n",
    "# data_train[data_train.label == 1 ] = data_train[data_train.label == 1].fillna(data_train[data_train.label == 1].mean()[mean])\n",
    "\n",
    "# #特征筛选\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# def data_scale(df):\n",
    "#     scaler = StandardScaler()\n",
    "#     return scaler.fit_transform(df.reshape(-1,1))\n",
    "                                \n",
    "\n",
    "\n",
    "# data_train['sum24-27'] = data_scale(data_train['f24']) + data_scale(data_train['f25']) + data_scale(data_train['f26']) + data_scale(data_train['f27']) \n",
    "\n",
    "# data_train['sum28-31'] = data_scale(data_train['f28']) + data_scale(data_train['f29']) + data_scale(data_train['f30']) + data_scale(data_train['f31'] )\n",
    "\n",
    "# data_train['sum32-35'] = data_scale(data_train['f32']) + data_scale(data_train['f33']) + data_scale(data_train['f34'] )+ data_scale(data_train['f35'] )\n",
    "                           \n",
    "# data_train['sum48-51'] = data_scale(data_train['f48']) + data_scale(data_train['f49']) + data_scale(data_train['f50'] )+ data_scale(data_train['f51'])\n",
    "\n",
    "# data_train['sum52-53'] = data_scale(data_train['f52']) + data_scale(data_train['f53'] )\n",
    "\n",
    "                                \n",
    "# data_train['sum61-63'] = data_scale(data_train['f61'] )+ data_scale(data_train['f62']) + data_scale(data_train['f63'])\n",
    "\n",
    "                         \n",
    "                                \n",
    "# data_train['sum72-75'] = data_scale(data_train['f72']) + data_scale(data_train['f73']) + data_scale(data_train['f74']) + data_scale(data_train['f75'])\n",
    "                           \n",
    "# data_train['sum102-103'] = data_scale(data_train['f102']) + data_scale(data_train['f103'] )\n",
    "                              \n",
    "# data_train['sum105-106'] = data_scale(data_train['f105']) + data_scale(data_train['f106'] )\n",
    "\n",
    "# data_train['sum107-108'] = data_scale(data_train['f107']) + data_scale(data_train['f108']) \n",
    "# data_train['sum109-110'] = data_scale(data_train['f109'] )+ data_scale(data_train['f110'] )\n",
    "\n",
    "# data_train['sum182-185'] = data_scale(data_train['f182'] )+ data_scale(data_train['f183'] )+ data_scale(data_train['f184']) + data_scale(data_train['f185'] )\n",
    "# data_train['sum192-193'] = data_scale(data_train['f192']) + data_scale(data_train['f193'])\n",
    "# data_train['sum204-207'] = data_scale(data_train['f204']) + data_scale(data_train['f205']) + data_scale(data_train['f206'] )+ data_scale(data_train['f207'] )\n",
    "# data_train['sum208-210'] = data_scale(data_train['f208']) + data_scale(data_train['f209']) + data_scale(data_train['f210'] )\n",
    "\n",
    "# data_train['sum215-218'] =data_scale( data_train['f215'] )+ data_scale(data_train['f216']) + data_scale(data_train['f217'] )+ data_scale(data_train['f218'] )\n",
    "# data_train['sum234-238'] = data_scale(data_train['f234']) + data_scale(data_train['f235']) + data_scale(data_train['f236']) + data_scale(data_train['f237']) + data_scale(data_train['f238'] )\n",
    "\n",
    "# data_train['sum259-266'] = data_scale(data_train['f259']) + data_scale(data_train['f260'] )+ data_scale(data_train['f261']) + data_scale(data_train['f262']) + data_scale(data_train['f263'])  + data_scale(data_train['f264'] )+data_scale( data_train['f265']) + data_scale(data_train['f266'] )\n",
    "# data_train['sum270-271'] = data_scale(data_train['f270']) + data_scale(data_train['f271'] )\n",
    "# data_train['sum274-276'] = data_scale(data_train['f274']) + data_scale(data_train['f275']) + data_scale(data_train['f276'])\n",
    "\n",
    "# need_scaler1 = [ 'f24','f25','f26','f27', 'f28','f29','f30','f31','f32','f33','f34','f35']\n",
    "# need_scaler2 = ['f48','f49','f50','f51', 'f52','f53','f61','f62','f63','f72','f73','f74','f75','f82','f102','f103']\n",
    "# need_scaler3 = ['f105','f106','f107','f108','f109','f110','f182','f183','f184','f185','f192','f193','f204','f205','f206','f207','f208','f209','f210']\n",
    "# need_scaler4 = ['f215','f216','f217', 'f218','f234','f235','f236','f237','f238','f259','f260','f261','f262','f263','f264','f265','f266','f270','f271','f274','f275','f276']\n",
    "\n",
    "# need_scaler = need_scaler1 + need_scaler2 + need_scaler3 + need_scaler4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f2',\n",
       " 'f5',\n",
       " 'f8',\n",
       " 'f10',\n",
       " 'f20',\n",
       " 'f21',\n",
       " 'f22',\n",
       " 'f23',\n",
       " 'f59',\n",
       " 'f60',\n",
       " 'f64',\n",
       " 'f66',\n",
       " 'f67',\n",
       " 'f68',\n",
       " 'f69',\n",
       " 'f70',\n",
       " 'f71',\n",
       " 'f81',\n",
       " 'f84',\n",
       " 'f92',\n",
       " 'f98',\n",
       " 'f123',\n",
       " 'f124',\n",
       " 'f125',\n",
       " 'f126',\n",
       " 'f127',\n",
       " 'f128',\n",
       " 'f129',\n",
       " 'f130',\n",
       " 'f131',\n",
       " 'f132',\n",
       " 'f133',\n",
       " 'f134',\n",
       " 'f135',\n",
       " 'f136',\n",
       " 'f137',\n",
       " 'f138',\n",
       " 'f139',\n",
       " 'f140',\n",
       " 'f141',\n",
       " 'f142',\n",
       " 'f143',\n",
       " 'f148',\n",
       " 'f154',\n",
       " 'f155',\n",
       " 'f157',\n",
       " 'f158',\n",
       " 'f159',\n",
       " 'f160',\n",
       " 'f161',\n",
       " 'f162',\n",
       " 'f163',\n",
       " 'f164',\n",
       " 'f165',\n",
       " 'f166',\n",
       " 'f167',\n",
       " 'f168',\n",
       " 'f169',\n",
       " 'f170',\n",
       " 'f171',\n",
       " 'f172',\n",
       " 'f173',\n",
       " 'f174',\n",
       " 'f175',\n",
       " 'f176',\n",
       " 'f177',\n",
       " 'f179',\n",
       " 'f180',\n",
       " 'f181',\n",
       " 'f186',\n",
       " 'f187',\n",
       " 'f188',\n",
       " 'f189',\n",
       " 'f190',\n",
       " 'f194',\n",
       " 'f195',\n",
       " 'f196',\n",
       " 'f197',\n",
       " 'f199',\n",
       " 'f200',\n",
       " 'f201',\n",
       " 'f202',\n",
       " 'f211',\n",
       " 'f212',\n",
       " 'f213',\n",
       " 'f214',\n",
       " 'f219',\n",
       " 'f220',\n",
       " 'f221',\n",
       " 'f222',\n",
       " 'f223',\n",
       " 'f224',\n",
       " 'f225',\n",
       " 'f226',\n",
       " 'f227',\n",
       " 'f228',\n",
       " 'f229',\n",
       " 'f230',\n",
       " 'f231',\n",
       " 'f232',\n",
       " 'f233',\n",
       " 'f239',\n",
       " 'f240',\n",
       " 'f241',\n",
       " 'f242',\n",
       " 'f243',\n",
       " 'f247',\n",
       " 'f248',\n",
       " 'f249',\n",
       " 'f250',\n",
       " 'f251',\n",
       " 'f252',\n",
       " 'f253',\n",
       " 'f254',\n",
       " 'f255',\n",
       " 'f256',\n",
       " 'f257',\n",
       " 'f258',\n",
       " 'f267',\n",
       " 'f268',\n",
       " 'f269',\n",
       " 'f272',\n",
       " 'f273',\n",
       " 'f279',\n",
       " 'f280',\n",
       " 'f281',\n",
       " 'f282',\n",
       " 'f284',\n",
       " 'f286',\n",
       " 'f287',\n",
       " 'f288',\n",
       " 'f289',\n",
       " 'f290',\n",
       " 'f291',\n",
       " 'f292',\n",
       " 'f293',\n",
       " 'f294',\n",
       " 'f295',\n",
       " 'f297',\n",
       " 'ifexist36-47',\n",
       " 'ifexist161-165',\n",
       " 'ifexist211-253']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "giveup = []\n",
    "for i in data_train.columns:\n",
    "    if abs(data_train[data_train.label == 1][i].mean()-data_train[data_train.label == 0][i].mean())/max(data_train[data_train.label == 1][i].mean(),data_train[data_train.label == 0][i].mean())<0.1:\n",
    "        giveup.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trian = data_train.drop(list(data_train.columns[36:48]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# data_test = pd.read_csv(\"F:/contest/ATEC/test.csv\")\n",
    "# test_id = data_test.iloc[:,0]\n",
    "# data_test = data_test.drop(['date', 'id'], axis = 1)\n",
    "dt = data_train\n",
    "data_train = data_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#计算缺失值个数\n",
    "# data_train['miss'] = data_train.apply(lambda x: x.isnull().sum(), axis = 1)\n",
    "# data_test['miss'] = data_test.applt(lambda x: x.isnull().sum())\n",
    "\n",
    "#添加缺失变量\n",
    "data_train['ifexist5'] = np.where(data_train.f5.isnull() == True, -1, 1 )\n",
    "data_train['ifexist20-23'] = np.where(data_train.f20.isnull() == True, -1, 1 )\n",
    "data_train['ifexist24-27'] = np.where(data_train.f24.isnull() == True, -1, 1)\n",
    "data_train['ifexist28-31'] = np.where(data_train.f28.isnull() == True, -1, 1)\n",
    "data_train['ifexist32-35'] = np.where(data_train.f32.isnull() == True, -1, 1)\n",
    "data_train['ifexist36-47'] = np.where(data_train.f36.isnull() == True, -1, 1)\n",
    "data_train['ifexist48-51'] = np.where(data_train.f48.isnull() == True, -1, 1)\n",
    "data_train['ifexist52-53'] = np.where(data_train.f52.isnull() == True, -1, 1)\n",
    "data_train['ifexist54-63'] = np.where(data_train.f54.isnull() == True, -1, 1)\n",
    "data_train['ifexist64-71'] = np.where(data_train.f64.isnull() == True, -1, 1)\n",
    "data_train['ifexist72-75'] = np.where(data_train.f72.isnull() == True, -1, 1)\n",
    "data_train['ifexist76-101'] = np.where(data_train.f76.isnull() == True, -1, 1)\n",
    "data_train['ifexist102-106'] = np.where(data_train.f102.isnull() == True, -1, 1)\n",
    "data_train['ifexist107-110'] = np.where(data_train.f107.isnull() == True, -1, 1)\n",
    "data_train['ifexist111-154'] = np.where(data_train.f111.isnull() == True, -1, 1)\n",
    "data_train['ifexist155-160'] = np.where(data_train.f155.isnull() == True, -1, 1)\n",
    "data_train['ifexist161-165'] = np.where(data_train.f161.isnull() == True, -1, 1)\n",
    "data_train['ifexist166-210'] = np.where(data_train.f166.isnull() == True, -1, 1)\n",
    "data_train['ifexist211-253'] = np.where(data_train.f211.isnull() == True, -1, 1)\n",
    "data_train['ifexist254-277'] = np.where(data_train.f254.isnull() == True, -1, 1)\n",
    "data_train['ifexist278-297'] = np.where(data_train.f278.isnull() == True, -1, 1)\n",
    "\n",
    "\n",
    "#缺失值填充\n",
    "\n",
    "\n",
    "\n",
    "data_train = data_train.fillna(data_train.mean())\n",
    "\n",
    "# data_train = data_train.fillna(data_train.mean()[mean])\n",
    "\n",
    "\n",
    "# #特征筛选\n",
    "\n",
    "                                \n",
    "\n",
    "\n",
    "# data_train['sum24-27'] = data_scale(data_train['f24']) + data_scale(data_train['f25']) + data_scale(data_train['f26']) + data_scale(data_train['f27']) \n",
    "\n",
    "# data_train['sum28-31'] = data_scale(data_train['f28']) + data_scale(data_train['f29']) + data_scale(data_train['f30']) + data_scale(data_train['f31'] )\n",
    "\n",
    "# data_train['sum32-35'] = data_scale(data_train['f32']) + data_scale(data_train['f33']) + data_scale(data_train['f34'] )+ data_scale(data_train['f35'] )\n",
    "                           \n",
    "# data_train['sum48-51'] = data_scale(data_train['f48']) + data_scale(data_train['f49']) + data_scale(data_train['f50'] )+ data_scale(data_train['f51'])\n",
    "\n",
    "# data_train['sum52-53'] = data_scale(data_train['f52']) + data_scale(data_train['f53'] )\n",
    "\n",
    "                                \n",
    "# data_train['sum61-63'] = data_scale(data_train['f61'] )+ data_scale(data_train['f62']) + data_scale(data_train['f63'])\n",
    "\n",
    "                         \n",
    "                                \n",
    "# data_train['sum72-75'] = data_scale(data_train['f72']) + data_scale(data_train['f73']) + data_scale(data_train['f74']) + data_scale(data_train['f75'])\n",
    "                           \n",
    "# data_train['sum102-103'] = data_scale(data_train['f102']) + data_scale(data_train['f103'] )\n",
    "                              \n",
    "# data_train['sum105-106'] = data_scale(data_train['f105']) + data_scale(data_train['f106'] )\n",
    "\n",
    "# data_train['sum107-108'] = data_scale(data_train['f107']) + data_scale(data_train['f108']) \n",
    "# data_train['sum109-110'] = data_scale(data_train['f109'] )+ data_scale(data_train['f110'] )\n",
    "\n",
    "# data_train['sum182-185'] = data_scale(data_train['f182'] )+ data_scale(data_train['f183'] )+ data_scale(data_train['f184']) + data_scale(data_train['f185'] )\n",
    "# data_train['sum192-193'] = data_scale(data_train['f192']) + data_scale(data_train['f193'])\n",
    "# data_train['sum204-207'] = data_scale(data_train['f204']) + data_scale(data_train['f205']) + data_scale(data_train['f206'] )+ data_scale(data_train['f207'] )\n",
    "# data_train['sum208-210'] = data_scale(data_train['f208']) + data_scale(data_train['f209']) + data_scale(data_train['f210'] )\n",
    "\n",
    "# data_train['sum215-218'] =data_scale( data_train['f215'] )+ data_scale(data_train['f216']) + data_scale(data_train['f217'] )+ data_scale(data_train['f218'] )\n",
    "# data_train['sum234-238'] = data_scale(data_train['f234']) + data_scale(data_train['f235']) + data_scale(data_train['f236']) + data_scale(data_train['f237']) + data_scale(data_train['f238'] )\n",
    "\n",
    "# data_train['sum259-266'] = data_scale(data_train['f259']) + data_scale(data_train['f260'] )+ data_scale(data_train['f261']) + data_scale(data_train['f262']) + data_scale(data_train['f263'])  + data_scale(data_train['f264'] )+data_scale( data_train['f265']) + data_scale(data_train['f266'] )\n",
    "# data_train['sum270-271'] = data_scale(data_train['f270']) + data_scale(data_train['f271'] )\n",
    "# data_train['sum274-276'] = data_scale(data_train['f274']) + data_scale(data_train['f275']) + data_scale(data_train['f276'])\n",
    "\n",
    "\n",
    "# data_train = data_train.drop(need_scaler, axis = 1)\n",
    "# dt = dt.drop(need_scaler, axis = 1)\n",
    "data_test = data_train\n",
    "data_train = dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "LGBM = lgb.LGBMClassifier(\n",
    "                         \n",
    "                         metric = 'auc',\n",
    "                         n_estimators=100, \n",
    "                         learning_rate=0.1, \n",
    "                         num_leaves=63, \n",
    "                         min_samples_split=2)\n",
    "df = data_train.as_matrix()\n",
    "X = df[:,1:]\n",
    "y = df[:,0]\n",
    "\n",
    "\n",
    "LGBM.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = data_test.as_matrix()\n",
    "res = LGBM.predict_proba(test)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = pd.DataFrame({'id':test_id, 'score': res})\n",
    "end.to_csv(\"F:/contest/ATEC/giveup36-48.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test = pd.read_csv(\"F:/contest/ATEC/test.csv\")\n",
    "test_id = data_test.iloc[:,0]\n",
    "data_test = data_test.drop(['date', 'id'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19e4154c4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.scatter( data_train.index[0:10000],data_train['label'][0:10000],s = 1, marker = '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C = 1.0 , penalty = 'l1')\n",
    "clf.fit(X,y)\n",
    "res = clf.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1646"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(res>0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 id\n",
      "0.0 date\n",
      "0.0 f1\n",
      "0.0 f2\n",
      "0.0 f3\n",
      "0.0 f4\n",
      "0.25029898224004815 f5\n",
      "0.0 f6\n",
      "0.0 f7\n",
      "0.0 f8\n",
      "0.0 f9\n",
      "0.0 f10\n",
      "0.0 f11\n",
      "0.0 f12\n",
      "0.0 f13\n",
      "0.0 f14\n",
      "0.0 f15\n",
      "0.0 f16\n",
      "0.0 f17\n",
      "0.0 f18\n",
      "0.0 f19\n",
      "0.24584272313837793 f20\n",
      "0.24584272313837793 f21\n",
      "0.24584272313837793 f22\n",
      "0.24584272313837793 f23\n",
      "0.24590984160042956 f24\n",
      "0.24590984160042956 f25\n",
      "0.24590984160042956 f26\n",
      "0.24590984160042956 f27\n",
      "0.2493186459155365 f28\n",
      "0.2493186459155365 f29\n",
      "0.2493186459155365 f30\n",
      "0.2493186459155365 f31\n",
      "0.3528214160775157 f32\n",
      "0.3528214160775157 f33\n",
      "0.3528214160775157 f34\n",
      "0.3528214160775157 f35\n",
      "0.9460347226177014 f36\n",
      "0.9460347226177014 f37\n",
      "0.9460347226177014 f38\n",
      "0.9460347226177014 f39\n",
      "0.9460347226177014 f40\n",
      "0.9460347226177014 f41\n",
      "0.9460347226177014 f42\n",
      "0.9460347226177014 f43\n",
      "0.9460347226177014 f44\n",
      "0.9460347226177014 f45\n",
      "0.9460347226177014 f46\n",
      "0.9460347226177014 f47\n",
      "0.3521400619930522 f48\n",
      "0.3521400619930522 f49\n",
      "0.3521400619930522 f50\n",
      "0.3521400619930522 f51\n",
      "0.24584272313837793 f52\n",
      "0.24584272313837793 f53\n",
      "0.3521400619930522 f54\n",
      "0.3521400619930522 f55\n",
      "0.3521400619930522 f56\n",
      "0.3521400619930522 f57\n",
      "0.3521400619930522 f58\n",
      "0.3521400619930522 f59\n",
      "0.3521400619930522 f60\n",
      "0.3521400619930522 f61\n",
      "0.3521400619930522 f62\n",
      "0.3521400619930522 f63\n",
      "0.6354206497067126 f64\n",
      "0.6354206497067126 f65\n",
      "0.6354206497067126 f66\n",
      "0.6354206497067126 f67\n",
      "0.6354206497067126 f68\n",
      "0.6354206497067126 f69\n",
      "0.6354206497067126 f70\n",
      "0.6354206497067126 f71\n",
      "0.6375460676716809 f72\n",
      "0.6375460676716809 f73\n",
      "0.6375460676716809 f74\n",
      "0.6375460676716809 f75\n",
      "0.6354206497067126 f76\n",
      "0.6354206497067126 f77\n",
      "0.6354206497067126 f78\n",
      "0.6354206497067126 f79\n",
      "0.6354206497067126 f80\n",
      "0.6354206497067126 f81\n",
      "0.6354206497067126 f82\n",
      "0.6354206497067126 f83\n",
      "0.6354206497067126 f84\n",
      "0.6354206497067126 f85\n",
      "0.6354206497067126 f86\n",
      "0.6354206497067126 f87\n",
      "0.6354206497067126 f88\n",
      "0.6354206497067126 f89\n",
      "0.6354206497067126 f90\n",
      "0.6354206497067126 f91\n",
      "0.6354206497067126 f92\n",
      "0.6354206497067126 f93\n",
      "0.6354206497067126 f94\n",
      "0.6354206497067126 f95\n",
      "0.6354206497067126 f96\n",
      "0.6354206497067126 f97\n",
      "0.6354206497067126 f98\n",
      "0.6354206497067126 f99\n",
      "0.6354206497067126 f100\n",
      "0.6354206497067126 f101\n",
      "0.6476402775856879 f102\n",
      "0.6476402775856879 f103\n",
      "0.6476402775856879 f104\n",
      "0.6476402775856879 f105\n",
      "0.6476402775856879 f106\n",
      "0.6375460676716809 f107\n",
      "0.6375460676716809 f108\n",
      "0.6375460676716809 f109\n",
      "0.6375460676716809 f110\n",
      "0.6354206497067126 f111\n",
      "0.6354206497067126 f112\n",
      "0.6354206497067126 f113\n",
      "0.6354206497067126 f114\n",
      "0.6354206497067126 f115\n",
      "0.6354206497067126 f116\n",
      "0.6354206497067126 f117\n",
      "0.6354206497067126 f118\n",
      "0.6354206497067126 f119\n",
      "0.6354206497067126 f120\n",
      "0.6354206497067126 f121\n",
      "0.6354206497067126 f122\n",
      "0.6354206497067126 f123\n",
      "0.6354206497067126 f124\n",
      "0.6354206497067126 f125\n",
      "0.6354206497067126 f126\n",
      "0.6354206497067126 f127\n",
      "0.6354206497067126 f128\n",
      "0.6354206497067126 f129\n",
      "0.6354206497067126 f130\n",
      "0.6354206497067126 f131\n",
      "0.6354206497067126 f132\n",
      "0.6354206497067126 f133\n",
      "0.6354206497067126 f134\n",
      "0.6354206497067126 f135\n",
      "0.6354206497067126 f136\n",
      "0.6354206497067126 f137\n",
      "0.6354206497067126 f138\n",
      "0.6354206497067126 f139\n",
      "0.6354206497067126 f140\n",
      "0.6354206497067126 f141\n",
      "0.6354206497067126 f142\n",
      "0.6354206497067126 f143\n",
      "0.6354206497067126 f144\n",
      "0.6354206497067126 f145\n",
      "0.6354206497067126 f146\n",
      "0.6354206497067126 f147\n",
      "0.6354206497067126 f148\n",
      "0.6354206497067126 f149\n",
      "0.6354206497067126 f150\n",
      "0.6354206497067126 f151\n",
      "0.6354206497067126 f152\n",
      "0.6354206497067126 f153\n",
      "0.6354206497067126 f154\n",
      "0.6375460676716809 f155\n",
      "0.6375460676716809 f156\n",
      "0.6375460676716809 f157\n",
      "0.6375460676716809 f158\n",
      "0.6375460676716809 f159\n",
      "0.6375460676716809 f160\n",
      "0.003465753313211354 f161\n",
      "0.003465753313211354 f162\n",
      "0.003465753313211354 f163\n",
      "0.003465753313211354 f164\n",
      "0.003465753313211354 f165\n",
      "0.17364563079150971 f166\n",
      "0.17364563079150971 f167\n",
      "0.17364563079150971 f168\n",
      "0.17364563079150971 f169\n",
      "0.17364563079150971 f170\n",
      "0.17364563079150971 f171\n",
      "0.17364563079150971 f172\n",
      "0.17364563079150971 f173\n",
      "0.17364563079150971 f174\n",
      "0.17364563079150971 f175\n",
      "0.17364563079150971 f176\n",
      "0.17364563079150971 f177\n",
      "0.17364563079150971 f178\n",
      "0.17364563079150971 f179\n",
      "0.17364563079150971 f180\n",
      "0.17364563079150971 f181\n",
      "0.17364563079150971 f182\n",
      "0.17364563079150971 f183\n",
      "0.17364563079150971 f184\n",
      "0.17364563079150971 f185\n",
      "0.17364563079150971 f186\n",
      "0.17364563079150971 f187\n",
      "0.17364563079150971 f188\n",
      "0.17364563079150971 f189\n",
      "0.17364563079150971 f190\n",
      "0.17364563079150971 f191\n",
      "0.17364563079150971 f192\n",
      "0.17364563079150971 f193\n",
      "0.17364563079150971 f194\n",
      "0.17364563079150971 f195\n",
      "0.17364563079150971 f196\n",
      "0.17364563079150971 f197\n",
      "0.17364563079150971 f198\n",
      "0.17364563079150971 f199\n",
      "0.17364563079150971 f200\n",
      "0.17364563079150971 f201\n",
      "0.17364563079150971 f202\n",
      "0.17364563079150971 f203\n",
      "0.17364563079150971 f204\n",
      "0.17364563079150971 f205\n",
      "0.17364563079150971 f206\n",
      "0.17364563079150971 f207\n",
      "0.17364563079150971 f208\n",
      "0.17364563079150971 f209\n",
      "0.17364563079150971 f210\n",
      "0.003465753313211354 f211\n",
      "0.003465753313211354 f212\n",
      "0.003465753313211354 f213\n",
      "0.003465753313211354 f214\n",
      "0.003465753313211354 f215\n",
      "0.003465753313211354 f216\n",
      "0.003465753313211354 f217\n",
      "0.003465753313211354 f218\n",
      "0.003465753313211354 f219\n",
      "0.003465753313211354 f220\n",
      "0.003465753313211354 f221\n",
      "0.003465753313211354 f222\n",
      "0.003465753313211354 f223\n",
      "0.003465753313211354 f224\n",
      "0.003465753313211354 f225\n",
      "0.003465753313211354 f226\n",
      "0.003465753313211354 f227\n",
      "0.003465753313211354 f228\n",
      "0.003465753313211354 f229\n",
      "0.003465753313211354 f230\n",
      "0.003465753313211354 f231\n",
      "0.003465753313211354 f232\n",
      "0.003465753313211354 f233\n",
      "0.003465753313211354 f234\n",
      "0.003465753313211354 f235\n",
      "0.003465753313211354 f236\n",
      "0.003465753313211354 f237\n",
      "0.003465753313211354 f238\n",
      "0.003465753313211354 f239\n",
      "0.003465753313211354 f240\n",
      "0.003465753313211354 f241\n",
      "0.003465753313211354 f242\n",
      "0.003465753313211354 f243\n",
      "0.003465753313211354 f244\n",
      "0.003465753313211354 f245\n",
      "0.003465753313211354 f246\n",
      "0.003465753313211354 f247\n",
      "0.003465753313211354 f248\n",
      "0.003465753313211354 f249\n",
      "0.003465753313211354 f250\n",
      "0.003465753313211354 f251\n",
      "0.003465753313211354 f252\n",
      "0.003465753313211354 f253\n",
      "0.17364563079150971 f254\n",
      "0.17364563079150971 f255\n",
      "0.17364563079150971 f256\n",
      "0.17364563079150971 f257\n",
      "0.17364563079150971 f258\n",
      "0.17364563079150971 f259\n",
      "0.17364563079150971 f260\n",
      "0.17364563079150971 f261\n",
      "0.17364563079150971 f262\n",
      "0.17364563079150971 f263\n",
      "0.17364563079150971 f264\n",
      "0.17364563079150971 f265\n",
      "0.17364563079150971 f266\n",
      "0.17364563079150971 f267\n",
      "0.17364563079150971 f268\n",
      "0.17364563079150971 f269\n",
      "0.17364563079150971 f270\n",
      "0.17364563079150971 f271\n",
      "0.17364563079150971 f272\n",
      "0.17364563079150971 f273\n",
      "0.17364563079150971 f274\n",
      "0.17364563079150971 f275\n",
      "0.17364563079150971 f276\n",
      "0.17364563079150971 f277\n",
      "0.24590984160042956 f278\n",
      "0.24590984160042956 f279\n",
      "0.24590984160042956 f280\n",
      "0.24590984160042956 f281\n",
      "0.24590984160042956 f282\n",
      "0.24590984160042956 f283\n",
      "0.24590984160042956 f284\n",
      "0.24590984160042956 f285\n",
      "0.24590984160042956 f286\n",
      "0.24590984160042956 f287\n",
      "0.24590984160042956 f288\n",
      "0.24590984160042956 f289\n",
      "0.24590984160042956 f290\n",
      "0.24590984160042956 f291\n",
      "0.24590984160042956 f292\n",
      "0.24590984160042956 f293\n",
      "0.24590984160042956 f294\n",
      "0.24590984160042956 f295\n",
      "0.24590984160042956 f296\n",
      "0.24590984160042956 f297\n"
     ]
    }
   ],
   "source": [
    "for i in data_test.columns:\n",
    "    print(data_test[i].isnull().sum()/491668, i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline: recall :0.57  auc: 0.78\n",
    "fill0: recall:   0.56  auc:0.77\n",
    "fill0_ifexist: recall:  0.56  auc: 0.78\n",
    "fill_mean:   recall:0.57  auc:0.78\n",
    "fill_median: recall:0.48  auc: 0.74\n",
    "fillmean_ifexist: recall: 0.59   auc: 0.79 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
