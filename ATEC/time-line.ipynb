{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"F:/contest/ATEC/train.csv\")\n",
    "data_test = pd.read_csv(\"F:/contest/ATEC/test.csv\")\n",
    "# unlabel = data_train[data_train.label == -1].drop(['id'], axis = 1)\n",
    "data_train = data_train[data_train.label != -1].drop(['id'], axis = 1).sort_values(by = 'date')\n",
    "# data_train = data_train.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = data_train.sort_values(by = 'date')\n",
    "\n",
    "\n",
    "data_train['ifexist5'] = np.where(data_train.f5.isnull() == True, -1, 1 )\n",
    "data_train['ifexist20-23'] = np.where(data_train.f20.isnull() == True, -1, 1 )\n",
    "data_train['ifexist24-27'] = np.where(data_train.f24.isnull() == True, -1, 1)\n",
    "data_train['ifexist28-31'] = np.where(data_train.f28.isnull() == True, -1, 1)\n",
    "data_train['ifexist32-35'] = np.where(data_train.f32.isnull() == True, -1, 1)\n",
    "data_train['ifexist36-47'] = np.where(data_train.f36.isnull() == True, -1, 1)\n",
    "data_train['ifexist48-51'] = np.where(data_train.f48.isnull() == True, -1, 1)\n",
    "data_train['ifexist52-53'] = np.where(data_train.f52.isnull() == True, -1, 1)\n",
    "data_train['ifexist54-63'] = np.where(data_train.f54.isnull() == True, -1, 1)\n",
    "data_train['ifexist64-71'] = np.where(data_train.f64.isnull() == True, -1, 1)\n",
    "data_train['ifexist72-75'] = np.where(data_train.f72.isnull() == True, -1, 1)\n",
    "data_train['ifexist76-101'] = np.where(data_train.f76.isnull() == True, -1, 1)\n",
    "data_train['ifexist102-106'] = np.where(data_train.f102.isnull() == True, -1, 1)\n",
    "data_train['ifexist107-110'] = np.where(data_train.f107.isnull() == True, -1, 1)\n",
    "data_train['ifexist111-154'] = np.where(data_train.f111.isnull() == True, -1, 1)\n",
    "data_train['ifexist155-160'] = np.where(data_train.f155.isnull() == True, -1, 1)\n",
    "data_train['ifexist161-165'] = np.where(data_train.f161.isnull() == True, -1, 1)\n",
    "data_train['ifexist166-210'] = np.where(data_train.f166.isnull() == True, -1, 1)\n",
    "data_train['ifexist211-253'] = np.where(data_train.f211.isnull() == True, -1, 1)\n",
    "data_train['ifexist254-277'] = np.where(data_train.f254.isnull() == True, -1, 1)\n",
    "data_train['ifexist278-297'] = np.where(data_train.f278.isnull() == True, -1, 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dt = data_train\n",
    "data_train = data_test\n",
    "data_train['ifexist5'] = np.where(data_train.f5.isnull() == True, -1, 1 )\n",
    "data_train['ifexist20-23'] = np.where(data_train.f20.isnull() == True, -1, 1 )\n",
    "data_train['ifexist24-27'] = np.where(data_train.f24.isnull() == True, -1, 1)\n",
    "data_train['ifexist28-31'] = np.where(data_train.f28.isnull() == True, -1, 1)\n",
    "data_train['ifexist32-35'] = np.where(data_train.f32.isnull() == True, -1, 1)\n",
    "data_train['ifexist36-47'] = np.where(data_train.f36.isnull() == True, -1, 1)\n",
    "data_train['ifexist48-51'] = np.where(data_train.f48.isnull() == True, -1, 1)\n",
    "data_train['ifexist52-53'] = np.where(data_train.f52.isnull() == True, -1, 1)\n",
    "data_train['ifexist54-63'] = np.where(data_train.f54.isnull() == True, -1, 1)\n",
    "data_train['ifexist64-71'] = np.where(data_train.f64.isnull() == True, -1, 1)\n",
    "data_train['ifexist72-75'] = np.where(data_train.f72.isnull() == True, -1, 1)\n",
    "data_train['ifexist76-101'] = np.where(data_train.f76.isnull() == True, -1, 1)\n",
    "data_train['ifexist102-106'] = np.where(data_train.f102.isnull() == True, -1, 1)\n",
    "data_train['ifexist107-110'] = np.where(data_train.f107.isnull() == True, -1, 1)\n",
    "data_train['ifexist111-154'] = np.where(data_train.f111.isnull() == True, -1, 1)\n",
    "data_train['ifexist155-160'] = np.where(data_train.f155.isnull() == True, -1, 1)\n",
    "data_train['ifexist161-165'] = np.where(data_train.f161.isnull() == True, -1, 1)\n",
    "data_train['ifexist166-210'] = np.where(data_train.f166.isnull() == True, -1, 1)\n",
    "data_train['ifexist211-253'] = np.where(data_train.f211.isnull() == True, -1, 1)\n",
    "data_train['ifexist254-277'] = np.where(data_train.f254.isnull() == True, -1, 1)\n",
    "data_train['ifexist278-297'] = np.where(data_train.f278.isnull() == True, -1, 1)\n",
    "\n",
    "data_test = data_train\n",
    "data_train = dt\n",
    "del dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(data_train.columns)[2:]\n",
    "giveup =[]\n",
    "for i in col:\n",
    "#     if data_train[i].isnull().sum() > 250000 :\n",
    "    if data_train[i].isnull().sum() > 200000:\n",
    "        giveup.append(i)\n",
    "        \n",
    "col1 = [i for i in col if i not in giveup]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = data_train.fillna(0)\n",
    "# data_test = data_test.fillna(0)\n",
    "num_train = 10\n",
    "train = []\n",
    "for i in range(num_train):\n",
    "    train.append(data_train.iloc[i*100000:i*100000+100000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "\n",
    "lg = []\n",
    "res = []\n",
    "for i in range(num_train):\n",
    "    lg.append(lgb.LGBMClassifier( max_depth = 8, num_leaves =180, n_estimators = 100,  min_child_samples=100))\n",
    "    lg[i].fit(train[i][col1].as_matrix(),train[i]['label'])\n",
    "    res.append(lg[i].predict_proba(data_test[col1].as_matrix())[:,1])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=-1, min_child_samples=100,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=100, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9572"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(res)/10 > 0.2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from mlxtend.classifier import StackingClassifier \n",
    "\n",
    "\n",
    "lg = []\n",
    "rf = []\n",
    "lr = []\n",
    "xgbmodel = []\n",
    "res = []\n",
    "\n",
    "\n",
    "for i in range(num_train):\n",
    "    lg.append(VotingClassifier(estimators = [('1',lgb.LGBMClassifier(max_depth = 8, n_estimators = 60+i%5*10)), \n",
    "                                             ('2', lgb.LGBMClassifier(max_depth = 5+i%5, n_estimators = 100))], voting = 'soft'))\n",
    "    rf.append(RandomForestClassifier(max_depth = 8, n_estimators = 30))\n",
    "    xgbmodel.append(VotingClassifier(estimators = [('1',xgb.XGBClassifier(max_depth = 8, n_estimators = 60+i%5*10)), \n",
    "                                             ('2', xgb.XGBClassifier(max_depth = 5+i%5, n_estimators = 100))], voting = 'soft'))\n",
    "    lr.append(LogisticRegression(C = 1.0))\n",
    "clf = []\n",
    "for i in range(num_train):\n",
    "#     clf.append( StackingClassifier(classifiers=[lg[i], xgbmodel[i]], \n",
    "#                           average_probas=False,  \n",
    "\n",
    "#                           meta_classifier=lr[i])) \n",
    "      clf.append(VotingClassifier(estimators = [('lg',lg[i]), ('xgb',xgbmodel[i])], voting = 'soft'))\n",
    "      clf[i].fit(train[i][col1].as_matrix(),train[i]['label'])\n",
    "      res.append(clf[i].predict_proba(data_test[col1].as_matrix())[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm as lgb\n",
    "lg1 = []\n",
    "res = []\n",
    "for i in range(10):\n",
    "    lg1.append(lgb.LGBMClassifier(max_depth = 8, n_estimators = 100))\n",
    "    lg1[i].fit(train[i][col1].as_matrix(),train[i]['label'])\n",
    "    res.append(lg1[i].predict_proba(data_test[col1].as_matrix())[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1450"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(res)/10>0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve \n",
    "\n",
    "def score(y,pred): \n",
    "    fpr, tpr, thresholds = roc_curve(y, pred, pos_label=1) \n",
    "    score1=0.4*tpr[np.where(fpr>=0.001)[0][0]]+0.3*tpr[np.where(fpr>=0.005)[0][0]]+0.3*tpr[np.where(fpr>=0.01)[0][0]] \n",
    "    return 'selfeval',score1, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.601802\tvalid_0's selfeval: 0.25746\n",
      "[2]\tvalid_0's binary_logloss: 0.527044\tvalid_0's selfeval: 0.258994\n",
      "[3]\tvalid_0's binary_logloss: 0.4648\tvalid_0's selfeval: 0.281671\n",
      "[4]\tvalid_0's binary_logloss: 0.412229\tvalid_0's selfeval: 0.284569\n",
      "[5]\tvalid_0's binary_logloss: 0.367334\tvalid_0's selfeval: 0.286275\n",
      "[6]\tvalid_0's binary_logloss: 0.328715\tvalid_0's selfeval: 0.286104\n",
      "[7]\tvalid_0's binary_logloss: 0.295303\tvalid_0's selfeval: 0.296164\n",
      "[8]\tvalid_0's binary_logloss: 0.266152\tvalid_0's selfeval: 0.293777\n",
      "[9]\tvalid_0's binary_logloss: 0.24071\tvalid_0's selfeval: 0.296675\n",
      "[10]\tvalid_0's binary_logloss: 0.218362\tvalid_0's selfeval: 0.301023\n",
      "[11]\tvalid_0's binary_logloss: 0.198672\tvalid_0's selfeval: 0.297272\n",
      "[12]\tvalid_0's binary_logloss: 0.181283\tvalid_0's selfeval: 0.301535\n",
      "[13]\tvalid_0's binary_logloss: 0.165893\tvalid_0's selfeval: 0.303495\n",
      "[14]\tvalid_0's binary_logloss: 0.152225\tvalid_0's selfeval: 0.299233\n",
      "[15]\tvalid_0's binary_logloss: 0.140094\tvalid_0's selfeval: 0.298636\n",
      "[16]\tvalid_0's binary_logloss: 0.129306\tvalid_0's selfeval: 0.305627\n",
      "[17]\tvalid_0's binary_logloss: 0.119696\tvalid_0's selfeval: 0.306053\n",
      "[18]\tvalid_0's binary_logloss: 0.111112\tvalid_0's selfeval: 0.303666\n",
      "[19]\tvalid_0's binary_logloss: 0.103503\tvalid_0's selfeval: 0.305456\n",
      "[20]\tvalid_0's binary_logloss: 0.0966651\tvalid_0's selfeval: 0.307417\n",
      "[21]\tvalid_0's binary_logloss: 0.0905616\tvalid_0's selfeval: 0.30682\n",
      "[22]\tvalid_0's binary_logloss: 0.0850879\tvalid_0's selfeval: 0.309804\n",
      "[23]\tvalid_0's binary_logloss: 0.0801927\tvalid_0's selfeval: 0.309378\n",
      "[24]\tvalid_0's binary_logloss: 0.0757742\tvalid_0's selfeval: 0.312106\n",
      "[25]\tvalid_0's binary_logloss: 0.0718501\tvalid_0's selfeval: 0.310401\n",
      "[26]\tvalid_0's binary_logloss: 0.0683232\tvalid_0's selfeval: 0.31364\n",
      "[27]\tvalid_0's binary_logloss: 0.0651176\tvalid_0's selfeval: 0.317391\n",
      "[28]\tvalid_0's binary_logloss: 0.0622714\tvalid_0's selfeval: 0.317903\n",
      "[29]\tvalid_0's binary_logloss: 0.0596839\tvalid_0's selfeval: 0.321313\n",
      "[30]\tvalid_0's binary_logloss: 0.0573917\tvalid_0's selfeval: 0.320972\n",
      "[31]\tvalid_0's binary_logloss: 0.0553538\tvalid_0's selfeval: 0.321739\n",
      "[32]\tvalid_0's binary_logloss: 0.0535312\tvalid_0's selfeval: 0.321228\n",
      "[33]\tvalid_0's binary_logloss: 0.0519172\tvalid_0's selfeval: 0.321398\n",
      "[34]\tvalid_0's binary_logloss: 0.0503799\tvalid_0's selfeval: 0.322847\n",
      "[35]\tvalid_0's binary_logloss: 0.0490402\tvalid_0's selfeval: 0.322165\n",
      "[36]\tvalid_0's binary_logloss: 0.0478274\tvalid_0's selfeval: 0.32046\n",
      "[37]\tvalid_0's binary_logloss: 0.0467387\tvalid_0's selfeval: 0.324041\n",
      "[38]\tvalid_0's binary_logloss: 0.0457413\tvalid_0's selfeval: 0.325916\n",
      "[39]\tvalid_0's binary_logloss: 0.0448753\tvalid_0's selfeval: 0.326428\n",
      "[40]\tvalid_0's binary_logloss: 0.0440865\tvalid_0's selfeval: 0.326172\n",
      "[41]\tvalid_0's binary_logloss: 0.0433402\tvalid_0's selfeval: 0.331202\n",
      "[42]\tvalid_0's binary_logloss: 0.042699\tvalid_0's selfeval: 0.33052\n",
      "[43]\tvalid_0's binary_logloss: 0.0421121\tvalid_0's selfeval: 0.329156\n",
      "[44]\tvalid_0's binary_logloss: 0.0416107\tvalid_0's selfeval: 0.329241\n",
      "[45]\tvalid_0's binary_logloss: 0.0411588\tvalid_0's selfeval: 0.33035\n",
      "[46]\tvalid_0's binary_logloss: 0.0406122\tvalid_0's selfeval: 0.331969\n",
      "[47]\tvalid_0's binary_logloss: 0.0402388\tvalid_0's selfeval: 0.332566\n",
      "[48]\tvalid_0's binary_logloss: 0.0398109\tvalid_0's selfeval: 0.33231\n",
      "[49]\tvalid_0's binary_logloss: 0.0394865\tvalid_0's selfeval: 0.332992\n",
      "[50]\tvalid_0's binary_logloss: 0.039196\tvalid_0's selfeval: 0.332737\n",
      "[51]\tvalid_0's binary_logloss: 0.0389296\tvalid_0's selfeval: 0.332822\n",
      "[52]\tvalid_0's binary_logloss: 0.0385182\tvalid_0's selfeval: 0.336402\n",
      "[53]\tvalid_0's binary_logloss: 0.0382506\tvalid_0's selfeval: 0.337596\n",
      "[54]\tvalid_0's binary_logloss: 0.0380479\tvalid_0's selfeval: 0.337852\n",
      "[55]\tvalid_0's binary_logloss: 0.0378066\tvalid_0's selfeval: 0.335209\n",
      "[56]\tvalid_0's binary_logloss: 0.0376419\tvalid_0's selfeval: 0.333845\n",
      "[57]\tvalid_0's binary_logloss: 0.0374684\tvalid_0's selfeval: 0.333163\n",
      "[58]\tvalid_0's binary_logloss: 0.03729\tvalid_0's selfeval: 0.334271\n",
      "[59]\tvalid_0's binary_logloss: 0.037153\tvalid_0's selfeval: 0.336658\n",
      "[60]\tvalid_0's binary_logloss: 0.0370003\tvalid_0's selfeval: 0.33717\n",
      "[61]\tvalid_0's binary_logloss: 0.0368389\tvalid_0's selfeval: 0.33896\n",
      "[62]\tvalid_0's binary_logloss: 0.0367525\tvalid_0's selfeval: 0.338704\n",
      "[63]\tvalid_0's binary_logloss: 0.0366402\tvalid_0's selfeval: 0.33896\n",
      "[64]\tvalid_0's binary_logloss: 0.0365141\tvalid_0's selfeval: 0.338022\n",
      "[65]\tvalid_0's binary_logloss: 0.0363821\tvalid_0's selfeval: 0.341006\n",
      "[66]\tvalid_0's binary_logloss: 0.0363252\tvalid_0's selfeval: 0.341688\n",
      "[67]\tvalid_0's binary_logloss: 0.0362285\tvalid_0's selfeval: 0.342285\n",
      "[68]\tvalid_0's binary_logloss: 0.0361601\tvalid_0's selfeval: 0.34399\n",
      "[69]\tvalid_0's binary_logloss: 0.0360393\tvalid_0's selfeval: 0.343819\n",
      "[70]\tvalid_0's binary_logloss: 0.035954\tvalid_0's selfeval: 0.345183\n",
      "[71]\tvalid_0's binary_logloss: 0.0359109\tvalid_0's selfeval: 0.346547\n",
      "[72]\tvalid_0's binary_logloss: 0.0358296\tvalid_0's selfeval: 0.346462\n",
      "[73]\tvalid_0's binary_logloss: 0.0357174\tvalid_0's selfeval: 0.347656\n",
      "[74]\tvalid_0's binary_logloss: 0.0356757\tvalid_0's selfeval: 0.346292\n",
      "[75]\tvalid_0's binary_logloss: 0.0356759\tvalid_0's selfeval: 0.347059\n",
      "[76]\tvalid_0's binary_logloss: 0.0356366\tvalid_0's selfeval: 0.348082\n",
      "[77]\tvalid_0's binary_logloss: 0.0355969\tvalid_0's selfeval: 0.347315\n",
      "[78]\tvalid_0's binary_logloss: 0.0355179\tvalid_0's selfeval: 0.348167\n",
      "[79]\tvalid_0's binary_logloss: 0.0354631\tvalid_0's selfeval: 0.347315\n",
      "[80]\tvalid_0's binary_logloss: 0.0354736\tvalid_0's selfeval: 0.347059\n",
      "[81]\tvalid_0's binary_logloss: 0.0352352\tvalid_0's selfeval: 0.347997\n",
      "[82]\tvalid_0's binary_logloss: 0.035243\tvalid_0's selfeval: 0.347144\n",
      "[83]\tvalid_0's binary_logloss: 0.0352149\tvalid_0's selfeval: 0.348167\n",
      "[84]\tvalid_0's binary_logloss: 0.0350279\tvalid_0's selfeval: 0.349361\n",
      "[85]\tvalid_0's binary_logloss: 0.0350041\tvalid_0's selfeval: 0.349531\n",
      "[86]\tvalid_0's binary_logloss: 0.0349716\tvalid_0's selfeval: 0.350043\n",
      "[87]\tvalid_0's binary_logloss: 0.034945\tvalid_0's selfeval: 0.349531\n",
      "[88]\tvalid_0's binary_logloss: 0.0348974\tvalid_0's selfeval: 0.34902\n",
      "[89]\tvalid_0's binary_logloss: 0.0349219\tvalid_0's selfeval: 0.350043\n",
      "[90]\tvalid_0's binary_logloss: 0.034927\tvalid_0's selfeval: 0.350298\n",
      "[91]\tvalid_0's binary_logloss: 0.0349148\tvalid_0's selfeval: 0.350554\n",
      "[92]\tvalid_0's binary_logloss: 0.0349194\tvalid_0's selfeval: 0.347997\n",
      "[93]\tvalid_0's binary_logloss: 0.0349044\tvalid_0's selfeval: 0.34919\n",
      "[94]\tvalid_0's binary_logloss: 0.0348889\tvalid_0's selfeval: 0.350554\n",
      "[95]\tvalid_0's binary_logloss: 0.0348862\tvalid_0's selfeval: 0.350554\n",
      "[96]\tvalid_0's binary_logloss: 0.0348672\tvalid_0's selfeval: 0.350298\n",
      "[97]\tvalid_0's binary_logloss: 0.0348492\tvalid_0's selfeval: 0.349702\n",
      "[98]\tvalid_0's binary_logloss: 0.0348326\tvalid_0's selfeval: 0.350128\n",
      "[99]\tvalid_0's binary_logloss: 0.0348012\tvalid_0's selfeval: 0.350298\n",
      "[100]\tvalid_0's binary_logloss: 0.0347831\tvalid_0's selfeval: 0.350725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=8, min_child_samples=100,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg.fit(data_train[col1].iloc[:900000].as_matrix(), data_train.label[:900000], eval_set = (data_train[col1].iloc[900000:].as_matrix(), data_train.label[900000:]), eval_metric = score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = pd.DataFrame({'id': data_test['id'],'score':sum(res)/10})\n",
    "end.to_csv(\"F:/contest/ATEC/timeline_xgb30lgb100_haveminchild_0.426+.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.00084274, 0.0312468 , 0.00036686, ..., 0.00056901, 0.00031004,\n",
       "        0.00055294]),\n",
       " array([0.00053304, 0.06112723, 0.00028243, ..., 0.00032297, 0.00039515,\n",
       "        0.00014219]),\n",
       " array([1.86102235e-03, 1.27090058e-01, 5.95219412e-04, ...,\n",
       "        2.00702861e-04, 4.48186683e-04, 1.13130259e-04]),\n",
       " array([1.67394872e-03, 1.61323439e-01, 5.06830644e-04, ...,\n",
       "        8.18434685e-04, 5.80480964e-04, 7.64105518e-05]),\n",
       " array([8.65605658e-04, 1.83115461e-01, 1.57741666e-03, ...,\n",
       "        1.45505803e-04, 3.12946538e-04, 8.23440036e-05]),\n",
       " array([3.62671543e-04, 5.78678477e-02, 8.93132720e-04, ...,\n",
       "        2.11298426e-04, 5.58534670e-04, 7.91286563e-05]),\n",
       " array([0.00041591, 0.10000658, 0.00088081, ..., 0.00028433, 0.00125431,\n",
       "        0.00010774]),\n",
       " array([7.95852579e-03, 5.11869595e-01, 6.98330943e-04, ...,\n",
       "        1.76605382e-04, 2.95090187e-03, 5.26755833e-05]),\n",
       " array([1.60666828e-03, 1.90686226e-01, 1.10125948e-03, ...,\n",
       "        5.95718729e-04, 6.44363982e-04, 1.31257140e-04]),\n",
       " array([0.00096124, 0.08558742, 0.00153154, ..., 0.00035997, 0.00231445,\n",
       "        0.00016507])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        learning_rate=0.1, max_depth=8, min_child_samples=100,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "        n_jobs=-1, num_leaves=31, objective=None, random_state=None,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lg1 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg2 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg3 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg4 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg5 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg6 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg7 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg8 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg9 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg10 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "\n",
    "\n",
    "lg1.fit(train1.iloc[:,2:].as_matrix(),train1['label'])\n",
    "lg2.fit(train2.iloc[:,2:].as_matrix(),train2['label'])\n",
    "lg3.fit(train3.iloc[:,2:].as_matrix(),train3['label'])\n",
    "lg4.fit(train4.iloc[:,2:].as_matrix(),train4['label'])\n",
    "lg5.fit(train5.iloc[:,2:].as_matrix(),train5['label'])\n",
    "lg6.fit(train6.iloc[:,2:].as_matrix(),train6['label'])\n",
    "lg7.fit(train7.iloc[:,2:].as_matrix(),train7['label'])\n",
    "lg8.fit(train8.iloc[:,2:].as_matrix(),train8['label'])\n",
    "lg9.fit(train9.iloc[:,2:].as_matrix(),train9['label'])\n",
    "lg10.fit(train10.iloc[:,2:].as_matrix(),train10['label'])\n",
    "\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "lg1 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg2 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg3 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg4 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg5 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg6 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg7 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg8 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg9 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg10 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg11 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg12 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg13 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg14 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg15 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg16 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg17 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg18 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg19 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "lg20 = lgb.LGBMClassifier(max_depth=8,n_estimators = 100,  min_child_samples=100)\n",
    "\n",
    "lg1.fit(train1[col1].as_matrix(),train1['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg2.fit(train2[col1].as_matrix(),train2['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg3.fit(train3[col1].as_matrix(),train3['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg4.fit(train4[col1].as_matrix(),train4['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg5.fit(train5[col1].as_matrix(),train5['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg6.fit(train6[col1].as_matrix(),train6['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg7.fit(train7[col1].as_matrix(),train7['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg8.fit(train8[col1].as_matrix(),train8['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg9.fit(train9[col1].as_matrix(),train9['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg10.fit(train10[col1].as_matrix(),train10['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg11.fit(train11[col1].as_matrix(),train11['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg12.fit(train12[col1].as_matrix(),train12['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg13.fit(train13[col1].as_matrix(),train13['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg14.fit(train14[col1].as_matrix(),train14['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg15.fit(train15[col1].as_matrix(),train15['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg16.fit(train16[col1].as_matrix(),train16['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg17.fit(train17[col1].as_matrix(),train17['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg18.fit(train18[col1].as_matrix(),train18['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg19.fit(train19[col1].as_matrix(),train19['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)\n",
    "lg20.fit(train20[col1].as_matrix(),train20['label'],eval_set = (data_train[col1].iloc[900000:990000].as_matrix(),data_train['label'][900000:990000]), eval_metric = score,verbose = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
